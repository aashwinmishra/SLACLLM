{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfLCHz2MWuv/2OMnE27HgU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HVosuTlllNaM"
      },
      "outputs": [],
      "source": [
        "!pip install transformers -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
        "\n",
        "import torch"
      ],
      "metadata": {
        "id": "ns_eubWhlQBJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xivJJLT7tKSl",
        "outputId": "16fb07b4-56c2-470a-ec5d-4450f7b2f979"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_inputs = [\n",
        "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "        \"I hate this so much!\",\n",
        "    ]\n",
        "\n",
        "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors='pt')"
      ],
      "metadata": {
        "id": "GejZTr9StxO2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**inputs)\n",
        "with torch.inference_mode():\n",
        "  fin = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "print(fin)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwPelOLnBA9p",
        "outputId": "8fa544cf-9ac6-4074-83e2-5e714e3c411d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.0195e-02, 9.5980e-01],\n",
            "        [9.9946e-01, 5.4418e-04]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5uBJ0p0BBEo",
        "outputId": "d8a85202-93a6-4d6b-f155-c37efed7435e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceClassifierOutput(loss=None, logits=tensor([[-1.5607,  1.6123],\n",
              "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "channels = 3000\n",
        "samples = 20\n",
        "\n",
        "weight = torch.ones((1, channels, 1, 1))\n",
        "image = torch.rand((samples, channels, 10, 10))\n",
        "\n",
        "noise = torch.randn((samples, 1, 10, 10))\n",
        "temp = weight * noise\n",
        "image_noisy = image + temp\n",
        "print(image.shape, temp.shape, image_noisy.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1LsHEm8_i2a",
        "outputId": "e323e807-25eb-4d56-bdc1-f3a9063d9e4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 3000, 10, 10]) torch.Size([20, 3000, 10, 10]) torch.Size([20, 3000, 10, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.abs(image - image_noisy).std(0).mean())\n",
        "print(torch.abs(image - image_noisy).std(1).mean())\n",
        "print(torch.abs(image - image_noisy).std(2).mean())\n",
        "print(torch.abs(image - image_noisy).std(3).mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4B6tYi4_nzo",
        "outputId": "18618aa2-5963-4a67-ff24-a779582f1a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.5843)\n",
            "tensor(2.4045e-08)\n",
            "tensor(0.5671)\n",
            "tensor(0.5714)\n"
          ]
        }
      ]
    }
  ]
}